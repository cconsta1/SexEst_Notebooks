{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "\n",
    "import os\n",
    "\n",
    "# data analysis and plotting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "# data processing and model validation\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, accuracy_score, classification_report, log_loss\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# classification libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, WhiteKernel, Matern, RationalQuadratic\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Importing imputation libs. \n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Hyperparameter optimization\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# exporting the models\n",
    "import pickle\n",
    "\n",
    "# parameter settings\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To change scientific numbers to float\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "\n",
    "# Increase the size of sns plots\n",
    "sns.set(rc={'figure.figsize':(12,10)})\n",
    "\n",
    "# import sys\n",
    "# !conda list Check the packages installed\n",
    "\n",
    "# Displaying all the rows/columns in a data set (the default option is not to show them)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and trim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the raw data\n",
    "\n",
    "raw_data_howell = pd.read_csv(\"datasets/Howell.csv\", header = 0, encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_howell_test = pd.read_csv(\"datasets/HowellTest.csv\", header = 0, encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>PopNum</th>\n",
       "      <th>Population</th>\n",
       "      <th>GOL</th>\n",
       "      <th>NOL</th>\n",
       "      <th>BNL</th>\n",
       "      <th>BBH</th>\n",
       "      <th>XCB</th>\n",
       "      <th>XFB</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>AUB</th>\n",
       "      <th>WCB</th>\n",
       "      <th>ASB</th>\n",
       "      <th>BPL</th>\n",
       "      <th>NPH</th>\n",
       "      <th>NLH</th>\n",
       "      <th>JUB</th>\n",
       "      <th>NLB</th>\n",
       "      <th>MAB</th>\n",
       "      <th>MDH</th>\n",
       "      <th>MDB</th>\n",
       "      <th>OBH</th>\n",
       "      <th>OBB</th>\n",
       "      <th>DKB</th>\n",
       "      <th>NDS</th>\n",
       "      <th>WNB</th>\n",
       "      <th>SIS</th>\n",
       "      <th>ZMB</th>\n",
       "      <th>SSS</th>\n",
       "      <th>FMB</th>\n",
       "      <th>NAS</th>\n",
       "      <th>EKB</th>\n",
       "      <th>DKS</th>\n",
       "      <th>IML</th>\n",
       "      <th>XML</th>\n",
       "      <th>MLS</th>\n",
       "      <th>WMH</th>\n",
       "      <th>SOS</th>\n",
       "      <th>GLS</th>\n",
       "      <th>STB</th>\n",
       "      <th>FRC</th>\n",
       "      <th>FRS</th>\n",
       "      <th>FRF</th>\n",
       "      <th>PAC</th>\n",
       "      <th>PAS</th>\n",
       "      <th>PAF</th>\n",
       "      <th>OCC</th>\n",
       "      <th>OCS</th>\n",
       "      <th>OCF</th>\n",
       "      <th>FOL</th>\n",
       "      <th>NAR</th>\n",
       "      <th>SSR</th>\n",
       "      <th>PRR</th>\n",
       "      <th>DKR</th>\n",
       "      <th>ZOR</th>\n",
       "      <th>FMR</th>\n",
       "      <th>EKR</th>\n",
       "      <th>ZMR</th>\n",
       "      <th>AVR</th>\n",
       "      <th>BRR</th>\n",
       "      <th>VRR</th>\n",
       "      <th>LAR</th>\n",
       "      <th>OSR</th>\n",
       "      <th>BAR</th>\n",
       "      <th>NAA</th>\n",
       "      <th>PRA</th>\n",
       "      <th>BAA</th>\n",
       "      <th>NBA</th>\n",
       "      <th>BBA</th>\n",
       "      <th>BRA</th>\n",
       "      <th>SSA</th>\n",
       "      <th>NFA</th>\n",
       "      <th>DKA</th>\n",
       "      <th>NDA</th>\n",
       "      <th>SIA</th>\n",
       "      <th>FRA</th>\n",
       "      <th>PAA</th>\n",
       "      <th>OCA</th>\n",
       "      <th>RFA</th>\n",
       "      <th>RPA</th>\n",
       "      <th>ROA</th>\n",
       "      <th>BSA</th>\n",
       "      <th>SBA</th>\n",
       "      <th>SLA</th>\n",
       "      <th>TBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NORSE</td>\n",
       "      <td>189</td>\n",
       "      <td>185</td>\n",
       "      <td>100</td>\n",
       "      <td>135</td>\n",
       "      <td>143</td>\n",
       "      <td>120</td>\n",
       "      <td>133</td>\n",
       "      <td>119</td>\n",
       "      <td>70</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>118</td>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>83</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>118</td>\n",
       "      <td>25</td>\n",
       "      <td>53</td>\n",
       "      <td>119</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>98</td>\n",
       "      <td>30</td>\n",
       "      <td>51</td>\n",
       "      <td>34</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>129</td>\n",
       "      <td>138</td>\n",
       "      <td>158</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "      <td>134</td>\n",
       "      <td>133</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NORSE</td>\n",
       "      <td>182</td>\n",
       "      <td>178</td>\n",
       "      <td>102</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>120</td>\n",
       "      <td>137</td>\n",
       "      <td>125</td>\n",
       "      <td>66</td>\n",
       "      <td>113</td>\n",
       "      <td>108</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>118</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>101</td>\n",
       "      <td>27</td>\n",
       "      <td>95</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "      <td>113</td>\n",
       "      <td>24</td>\n",
       "      <td>59</td>\n",
       "      <td>93</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>93</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>35</td>\n",
       "      <td>79</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>124</td>\n",
       "      <td>141</td>\n",
       "      <td>153</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NORSE</td>\n",
       "      <td>191</td>\n",
       "      <td>187</td>\n",
       "      <td>102</td>\n",
       "      <td>123</td>\n",
       "      <td>140</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>125</td>\n",
       "      <td>74</td>\n",
       "      <td>112</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>53</td>\n",
       "      <td>112</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>90</td>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>107</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>118</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>88</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>102</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>38</td>\n",
       "      <td>72</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>152</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>129</td>\n",
       "      <td>137</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NORSE</td>\n",
       "      <td>191</td>\n",
       "      <td>188</td>\n",
       "      <td>100</td>\n",
       "      <td>127</td>\n",
       "      <td>141</td>\n",
       "      <td>123</td>\n",
       "      <td>135</td>\n",
       "      <td>127</td>\n",
       "      <td>71</td>\n",
       "      <td>113</td>\n",
       "      <td>95</td>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>114</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>98</td>\n",
       "      <td>16</td>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "      <td>109</td>\n",
       "      <td>26</td>\n",
       "      <td>47</td>\n",
       "      <td>116</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>94</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>98</td>\n",
       "      <td>81</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>73</td>\n",
       "      <td>72</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>71</td>\n",
       "      <td>46</td>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>128</td>\n",
       "      <td>144</td>\n",
       "      <td>157</td>\n",
       "      <td>98</td>\n",
       "      <td>90</td>\n",
       "      <td>128</td>\n",
       "      <td>135</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NORSE</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>97</td>\n",
       "      <td>128</td>\n",
       "      <td>138</td>\n",
       "      <td>117</td>\n",
       "      <td>129</td>\n",
       "      <td>121</td>\n",
       "      <td>69</td>\n",
       "      <td>111</td>\n",
       "      <td>90</td>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>115</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>91</td>\n",
       "      <td>21</td>\n",
       "      <td>96</td>\n",
       "      <td>18</td>\n",
       "      <td>97</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>102</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>113</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>94</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>94</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>71</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>75</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>130</td>\n",
       "      <td>139</td>\n",
       "      <td>150</td>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>133</td>\n",
       "      <td>130</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Sex  PopNum Population  GOL  NOL  BNL  BBH  XCB  XFB  ZYB  AUB  WCB  \\\n",
       "0   1   M       1      NORSE  189  185  100  135  143  120  133  119   70   \n",
       "1   2   M       1      NORSE  182  178  102  139  145  120  137  125   66   \n",
       "2   3   M       1      NORSE  191  187  102  123  140  114  134  125   74   \n",
       "3   4   M       1      NORSE  191  188  100  127  141  123  135  127   71   \n",
       "4   5   M       1      NORSE  178  177   97  128  138  117  129  121   69   \n",
       "\n",
       "   ASB  BPL  NPH  NLH  JUB  NLB  MAB  MDH  MDB  OBH  OBB  DKB  NDS   WNB  SIS  \\\n",
       "0  112   96   66   50  118   26   63   31   13   31   42   22   12   9.5  4.9   \n",
       "1  113  108   64   48  118   25   72   19   13   28   39   21    9  10.8  4.5   \n",
       "2  112  102   67   53  112   23   65   28   14   33   41   20   13   8.1  4.5   \n",
       "3  113   95   76   53  114   26   62   25   12   35   40   23   10   8.8  4.4   \n",
       "4  111   90   67   51  115   24   64   26   14   32   39   21   11   8.9  5.4   \n",
       "\n",
       "   ZMB  SSS  FMB  NAS  EKB  DKS  IML  XML  MLS  WMH  SOS  GLS  STB  FRC  FRS  \\\n",
       "0   83   20  100   19  100    8   42   57   13   24    7    4  115  118   25   \n",
       "1  101   27   95   17   96    9   32   53   10   23    6    4  117  116   28   \n",
       "2   90   24   98   19   97   10   35   56   10   24    6    4  112  107   25   \n",
       "3   94   23   98   16   99    8   34   52   11   22    8    3  116  109   26   \n",
       "4   91   21   96   18   97   10   35   52   12   27    5    2  116  102   22   \n",
       "\n",
       "   FRF  PAC  PAS  PAF  OCC  OCS  OCF  FOL  NAR  SSR  PRR  DKR  ZOR  FMR  EKR  \\\n",
       "0   53  119   26   62   98   30   51   34   96   95  100   84   81   74   73   \n",
       "1   55  113   24   59   93   27   39   34   93  102  108   84   84   76   73   \n",
       "2   47  118   23   59   88   30   45   41   96   96  102   82   82   77   72   \n",
       "3   47  116   24   57   94   34   50   38   92   93   98   81   79   79   73   \n",
       "4   45  113   26   62   94   32   40   34   91   92   94   79   79   72   69   \n",
       "\n",
       "   ZMR  AVR  BRR  VRR  LAR  OSR  BAR  NAA  PRA  BAA  NBA  BBA  BRA  SSA  NFA  \\\n",
       "0   76   83    0  122    0    0    0   67   74   39   76   58   46  129  138   \n",
       "1   74   82    0  124    0    0    0   77   67   35   79   55   46  124  141   \n",
       "2   70   82    0  116    0    0    0   71   71   38   72   56   52  124  138   \n",
       "3   72   77    0  118    0    0    0   64   71   46   75   56   49  128  144   \n",
       "4   71   76    0  118    0    0    0   64   75   42   80   52   48  130  139   \n",
       "\n",
       "   DKA  NDA  SIA  FRA  PAA  OCA  RFA  RPA  ROA  BSA  SBA  SLA  TBA  \n",
       "0  158   85   88  134  133  117    0    0    0    0    0    0    0  \n",
       "1  153   99  100  128  134  119    0    0    0    0    0    0    0  \n",
       "2  152   75   84  129  137  111    0    0    0    0    0    0    0  \n",
       "3  157   98   90  128  135  108    0    0    0    0    0    0    0  \n",
       "4  150   87   79  133  130  111    0    0    0    0    0    0    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_howell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2524, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measured_data_howell = raw_data_howell.loc[:,\"GOL\":\"TBA\"]\n",
    "\n",
    "model_cols_howell = [\n",
    "    'GOL', \n",
    "    'NOL', \n",
    "    'BNL', \n",
    "    'BBH', \n",
    "    'XCB', \n",
    "    'XFB', \n",
    "    'ZYB', \n",
    "    'AUB', \n",
    "    'WCB', \n",
    "    'ASB',\n",
    "    'BPL', \n",
    "    'NPH', \n",
    "    'NLH', \n",
    "    'JUB', \n",
    "    'NLB', \n",
    "    'MAB', \n",
    "    'MDH', \n",
    "    'MDB', \n",
    "    'OBH', \n",
    "    'OBB',\n",
    "    'DKB', \n",
    "    'ZMB', \n",
    "    'FMB', \n",
    "    'EKB', \n",
    "    'IML', \n",
    "    'XML', \n",
    "    'WMH', \n",
    "    'STB', \n",
    "    'FRC', \n",
    "    'PAC', \n",
    "    'OCC', \n",
    "    'FOL'\n",
    "]\n",
    "             \n",
    "model_data_howell = measured_data_howell.drop(columns=[col for col in measured_data_howell if col not in model_cols_howell])\n",
    "\n",
    "model_data_howell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measured_data_howell_test = raw_data_howell_test.loc[:,\"GOL\":\"TBA\"]\n",
    "\n",
    "model_data_howell_test = measured_data_howell_test.drop(columns=[col for col in measured_data_howell_test if col not in model_cols_howell])\n",
    "\n",
    "model_data_howell_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Sex column\n",
    "\n",
    "model_data_howell_test = pd.concat([model_data_howell_test.loc[:,:],raw_data_howell_test.loc[:,\"Sex\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOL</th>\n",
       "      <th>NOL</th>\n",
       "      <th>BNL</th>\n",
       "      <th>BBH</th>\n",
       "      <th>XCB</th>\n",
       "      <th>XFB</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>AUB</th>\n",
       "      <th>WCB</th>\n",
       "      <th>ASB</th>\n",
       "      <th>BPL</th>\n",
       "      <th>NPH</th>\n",
       "      <th>NLH</th>\n",
       "      <th>JUB</th>\n",
       "      <th>NLB</th>\n",
       "      <th>MAB</th>\n",
       "      <th>MDH</th>\n",
       "      <th>MDB</th>\n",
       "      <th>OBH</th>\n",
       "      <th>OBB</th>\n",
       "      <th>DKB</th>\n",
       "      <th>ZMB</th>\n",
       "      <th>FMB</th>\n",
       "      <th>EKB</th>\n",
       "      <th>IML</th>\n",
       "      <th>XML</th>\n",
       "      <th>WMH</th>\n",
       "      <th>STB</th>\n",
       "      <th>FRC</th>\n",
       "      <th>PAC</th>\n",
       "      <th>OCC</th>\n",
       "      <th>FOL</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190</td>\n",
       "      <td>185</td>\n",
       "      <td>100</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>119</td>\n",
       "      <td>136</td>\n",
       "      <td>125</td>\n",
       "      <td>82</td>\n",
       "      <td>114</td>\n",
       "      <td>96</td>\n",
       "      <td>71</td>\n",
       "      <td>50</td>\n",
       "      <td>117</td>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>98</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>38</td>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>126</td>\n",
       "      <td>102</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176</td>\n",
       "      <td>174</td>\n",
       "      <td>102</td>\n",
       "      <td>134</td>\n",
       "      <td>126</td>\n",
       "      <td>103</td>\n",
       "      <td>124</td>\n",
       "      <td>113</td>\n",
       "      <td>64</td>\n",
       "      <td>108</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>45</td>\n",
       "      <td>111</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>23</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>105</td>\n",
       "      <td>101</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>179</td>\n",
       "      <td>178</td>\n",
       "      <td>95</td>\n",
       "      <td>123</td>\n",
       "      <td>141</td>\n",
       "      <td>112</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>72</td>\n",
       "      <td>108</td>\n",
       "      <td>94</td>\n",
       "      <td>62</td>\n",
       "      <td>50</td>\n",
       "      <td>113</td>\n",
       "      <td>29</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>108</td>\n",
       "      <td>106</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>101</td>\n",
       "      <td>130</td>\n",
       "      <td>141</td>\n",
       "      <td>125</td>\n",
       "      <td>128</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>115</td>\n",
       "      <td>102</td>\n",
       "      <td>63</td>\n",
       "      <td>49</td>\n",
       "      <td>116</td>\n",
       "      <td>28</td>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>114</td>\n",
       "      <td>130</td>\n",
       "      <td>106</td>\n",
       "      <td>38</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183</td>\n",
       "      <td>182</td>\n",
       "      <td>96</td>\n",
       "      <td>124</td>\n",
       "      <td>137</td>\n",
       "      <td>121</td>\n",
       "      <td>123</td>\n",
       "      <td>115</td>\n",
       "      <td>78</td>\n",
       "      <td>107</td>\n",
       "      <td>91</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>110</td>\n",
       "      <td>29</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>178</td>\n",
       "      <td>175</td>\n",
       "      <td>98</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>117</td>\n",
       "      <td>134</td>\n",
       "      <td>125</td>\n",
       "      <td>74</td>\n",
       "      <td>107</td>\n",
       "      <td>92</td>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>111</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>92</td>\n",
       "      <td>36</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>112</td>\n",
       "      <td>108</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>176</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>138</td>\n",
       "      <td>143</td>\n",
       "      <td>123</td>\n",
       "      <td>138</td>\n",
       "      <td>128</td>\n",
       "      <td>72</td>\n",
       "      <td>109</td>\n",
       "      <td>97</td>\n",
       "      <td>73</td>\n",
       "      <td>50</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>35</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>123</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>181</td>\n",
       "      <td>175</td>\n",
       "      <td>101</td>\n",
       "      <td>132</td>\n",
       "      <td>137</td>\n",
       "      <td>114</td>\n",
       "      <td>139</td>\n",
       "      <td>127</td>\n",
       "      <td>77</td>\n",
       "      <td>105</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>124</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>99</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "      <td>59</td>\n",
       "      <td>25</td>\n",
       "      <td>108</td>\n",
       "      <td>111</td>\n",
       "      <td>108</td>\n",
       "      <td>95</td>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>180</td>\n",
       "      <td>177</td>\n",
       "      <td>109</td>\n",
       "      <td>146</td>\n",
       "      <td>145</td>\n",
       "      <td>122</td>\n",
       "      <td>146</td>\n",
       "      <td>134</td>\n",
       "      <td>76</td>\n",
       "      <td>103</td>\n",
       "      <td>99</td>\n",
       "      <td>76</td>\n",
       "      <td>54</td>\n",
       "      <td>125</td>\n",
       "      <td>25</td>\n",
       "      <td>67</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "      <td>106</td>\n",
       "      <td>104</td>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>28</td>\n",
       "      <td>115</td>\n",
       "      <td>114</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>174</td>\n",
       "      <td>172</td>\n",
       "      <td>99</td>\n",
       "      <td>138</td>\n",
       "      <td>146</td>\n",
       "      <td>125</td>\n",
       "      <td>141</td>\n",
       "      <td>130</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>98</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>125</td>\n",
       "      <td>28</td>\n",
       "      <td>65</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>108</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>114</td>\n",
       "      <td>104</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GOL  NOL  BNL  BBH  XCB  XFB  ZYB  AUB  WCB  ASB  BPL  NPH  NLH  JUB  \\\n",
       "0    190  185  100  141  141  119  136  125   82  114   96   71   50  117   \n",
       "1    176  174  102  134  126  103  124  113   64  108  100   63   45  111   \n",
       "2    179  178   95  123  141  112  129  110   72  108   94   62   50  113   \n",
       "3    199  198  101  130  141  125  128  120   80  115  102   63   49  116   \n",
       "4    183  182   96  124  137  121  123  115   78  107   91   58   48  110   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "519  178  175   98  135  136  117  134  125   74  107   92   67   51  111   \n",
       "520  176  170  100  138  143  123  138  128   72  109   97   73   50  120   \n",
       "521  181  175  101  132  137  114  139  127   77  105   97   66   46  124   \n",
       "522  180  177  109  146  145  122  146  134   76  103   99   76   54  125   \n",
       "523  174  172   99  138  146  125  141  130   75  108   98   72   53  125   \n",
       "\n",
       "     NLB  MAB  MDH  MDB  OBH  OBB  DKB  ZMB  FMB  EKB  IML  XML  WMH  STB  \\\n",
       "0     26   63   30   18   31   41   20   98  102  101   38   58   27  117   \n",
       "1     24   63   26   10   32   40   22   95  100   99   36   51   23  100   \n",
       "2     29   65   30   11   35   42   25   99  100  104   32   46   19  108   \n",
       "3     28   64   26   11   35   42   26   92  105  105   45   59   19  124   \n",
       "4     29   60   25   12   31   39   26   91  100   99   36   49   18  114   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "519   23   65   25   10   32   38   22   88   93   92   36   52   20  112   \n",
       "520   26   65   30   13   35   40   23   94  100   99   35   54   25  123   \n",
       "521   26   62   34   15   33   41   24   99  103  104   36   59   25  108   \n",
       "522   25   67   31   12   36   43   26   99  106  104   38   56   28  115   \n",
       "523   28   65   27   13   36   39   25  108  100  102   40   58   27  123   \n",
       "\n",
       "     FRC  PAC  OCC  FOL Sex  \n",
       "0    115  126  102   35   M  \n",
       "1    102  105  101   34   M  \n",
       "2    106  112   96   35   M  \n",
       "3    114  130  106   38   F  \n",
       "4    115  112   92   41   M  \n",
       "..   ...  ...  ...  ...  ..  \n",
       "519  108  103  103   39   M  \n",
       "520  117  116   96   32   M  \n",
       "521  111  108   95   38   M  \n",
       "522  114  104  104   39   M  \n",
       "523  114  104  100   36   M  \n",
       "\n",
       "[524 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_howell_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOL</th>\n",
       "      <th>NOL</th>\n",
       "      <th>BNL</th>\n",
       "      <th>BBH</th>\n",
       "      <th>XCB</th>\n",
       "      <th>XFB</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>AUB</th>\n",
       "      <th>WCB</th>\n",
       "      <th>ASB</th>\n",
       "      <th>BPL</th>\n",
       "      <th>NPH</th>\n",
       "      <th>NLH</th>\n",
       "      <th>JUB</th>\n",
       "      <th>NLB</th>\n",
       "      <th>MAB</th>\n",
       "      <th>MDH</th>\n",
       "      <th>MDB</th>\n",
       "      <th>OBH</th>\n",
       "      <th>OBB</th>\n",
       "      <th>DKB</th>\n",
       "      <th>ZMB</th>\n",
       "      <th>FMB</th>\n",
       "      <th>EKB</th>\n",
       "      <th>IML</th>\n",
       "      <th>XML</th>\n",
       "      <th>WMH</th>\n",
       "      <th>STB</th>\n",
       "      <th>FRC</th>\n",
       "      <th>PAC</th>\n",
       "      <th>OCC</th>\n",
       "      <th>FOL</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>185</td>\n",
       "      <td>100</td>\n",
       "      <td>135</td>\n",
       "      <td>143</td>\n",
       "      <td>120</td>\n",
       "      <td>133</td>\n",
       "      <td>119</td>\n",
       "      <td>70</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>118</td>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>24</td>\n",
       "      <td>115</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>98</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182</td>\n",
       "      <td>178</td>\n",
       "      <td>102</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>120</td>\n",
       "      <td>137</td>\n",
       "      <td>125</td>\n",
       "      <td>66</td>\n",
       "      <td>113</td>\n",
       "      <td>108</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>118</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>101</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>113</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>187</td>\n",
       "      <td>102</td>\n",
       "      <td>123</td>\n",
       "      <td>140</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>125</td>\n",
       "      <td>74</td>\n",
       "      <td>112</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>53</td>\n",
       "      <td>112</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>24</td>\n",
       "      <td>112</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191</td>\n",
       "      <td>188</td>\n",
       "      <td>100</td>\n",
       "      <td>127</td>\n",
       "      <td>141</td>\n",
       "      <td>123</td>\n",
       "      <td>135</td>\n",
       "      <td>127</td>\n",
       "      <td>71</td>\n",
       "      <td>113</td>\n",
       "      <td>95</td>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>114</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>34</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>116</td>\n",
       "      <td>109</td>\n",
       "      <td>116</td>\n",
       "      <td>94</td>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>97</td>\n",
       "      <td>128</td>\n",
       "      <td>138</td>\n",
       "      <td>117</td>\n",
       "      <td>129</td>\n",
       "      <td>121</td>\n",
       "      <td>69</td>\n",
       "      <td>111</td>\n",
       "      <td>90</td>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>115</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>91</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>116</td>\n",
       "      <td>102</td>\n",
       "      <td>113</td>\n",
       "      <td>94</td>\n",
       "      <td>34</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>159</td>\n",
       "      <td>158</td>\n",
       "      <td>89</td>\n",
       "      <td>125</td>\n",
       "      <td>128</td>\n",
       "      <td>101</td>\n",
       "      <td>117</td>\n",
       "      <td>106</td>\n",
       "      <td>64</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "      <td>104</td>\n",
       "      <td>101</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>87</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>101</td>\n",
       "      <td>113</td>\n",
       "      <td>102</td>\n",
       "      <td>62</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>105</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>95</td>\n",
       "      <td>104</td>\n",
       "      <td>101</td>\n",
       "      <td>88</td>\n",
       "      <td>32</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>89</td>\n",
       "      <td>121</td>\n",
       "      <td>129</td>\n",
       "      <td>106</td>\n",
       "      <td>117</td>\n",
       "      <td>112</td>\n",
       "      <td>69</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "      <td>105</td>\n",
       "      <td>24</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>102</td>\n",
       "      <td>105</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>172</td>\n",
       "      <td>170</td>\n",
       "      <td>92</td>\n",
       "      <td>118</td>\n",
       "      <td>137</td>\n",
       "      <td>110</td>\n",
       "      <td>114</td>\n",
       "      <td>106</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>105</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>17</td>\n",
       "      <td>104</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>89</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>88</td>\n",
       "      <td>116</td>\n",
       "      <td>130</td>\n",
       "      <td>105</td>\n",
       "      <td>115</td>\n",
       "      <td>103</td>\n",
       "      <td>61</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "      <td>53</td>\n",
       "      <td>41</td>\n",
       "      <td>104</td>\n",
       "      <td>21</td>\n",
       "      <td>56</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>104</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>85</td>\n",
       "      <td>32</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2524 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GOL  NOL  BNL  BBH  XCB  XFB  ZYB  AUB  WCB  ASB  BPL  NPH  NLH  JUB  \\\n",
       "0     189  185  100  135  143  120  133  119   70  112   96   66   50  118   \n",
       "1     182  178  102  139  145  120  137  125   66  113  108   64   48  118   \n",
       "2     191  187  102  123  140  114  134  125   74  112  102   67   53  112   \n",
       "3     191  188  100  127  141  123  135  127   71  113   95   76   53  114   \n",
       "4     178  177   97  128  138  117  129  121   69  111   90   67   51  115   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2519  159  158   89  125  128  101  117  106   64   91   92   58   45  106   \n",
       "2520  156  156   87  123  124  101  113  102   62   92   90   54   43  105   \n",
       "2521  160  160   89  121  129  106  117  112   69   99   95   55   42  105   \n",
       "2522  172  170   92  118  137  110  114  106   65   95   93   60   46  105   \n",
       "2523  153  153   88  116  130  105  115  103   61   95   92   53   41  104   \n",
       "\n",
       "      NLB  MAB  MDH  MDB  OBH  OBB  DKB  ZMB  FMB  EKB  IML  XML  WMH  STB  \\\n",
       "0      26   63   31   13   31   42   22   83  100  100   42   57   24  115   \n",
       "1      25   72   19   13   28   39   21  101   95   96   32   53   23  117   \n",
       "2      23   65   28   14   33   41   20   90   98   97   35   56   24  112   \n",
       "3      26   62   25   12   35   40   23   94   98   99   34   52   22  116   \n",
       "4      24   64   26   14   32   39   21   91   96   97   35   52   27  116   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2519   24   55   19    7   32   38   20   87   89   91   36   45   16   98   \n",
       "2520   24   57   21   12   31   36   20   89   84   89   34   48   16   95   \n",
       "2521   24   60   24   16   32   35   21   88   88   90   35   48   20  102   \n",
       "2522   26   57   22    8   33   37   19   86   88   91   31   46   17  104   \n",
       "2523   21   56   21   10   29   35   18   89   86   87   25   40   19  104   \n",
       "\n",
       "      FRC  PAC  OCC  FOL Sex  \n",
       "0     118  119   98   34   M  \n",
       "1     116  113   93   34   M  \n",
       "2     107  118   88   41   M  \n",
       "3     109  116   94   38   M  \n",
       "4     102  113   94   34   M  \n",
       "...   ...  ...  ...  ...  ..  \n",
       "2519  104  101   89   30   F  \n",
       "2520  104  101   88   32   F  \n",
       "2521  105  101   90   33   F  \n",
       "2522  103  104   89   33   F  \n",
       "2523   97   98   85   32   F  \n",
       "\n",
       "[2524 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the Sex column\n",
    "\n",
    "model_data_howell = pd.concat([model_data_howell.loc[:,:],raw_data_howell.loc[:,\"Sex\"]],axis=1)\n",
    "\n",
    "model_data_howell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset using the chosen features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOL</th>\n",
       "      <th>NOL</th>\n",
       "      <th>BNL</th>\n",
       "      <th>BBH</th>\n",
       "      <th>XCB</th>\n",
       "      <th>XFB</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>AUB</th>\n",
       "      <th>WCB</th>\n",
       "      <th>ASB</th>\n",
       "      <th>BPL</th>\n",
       "      <th>NPH</th>\n",
       "      <th>NLH</th>\n",
       "      <th>JUB</th>\n",
       "      <th>NLB</th>\n",
       "      <th>MAB</th>\n",
       "      <th>MDH</th>\n",
       "      <th>MDB</th>\n",
       "      <th>OBH</th>\n",
       "      <th>OBB</th>\n",
       "      <th>DKB</th>\n",
       "      <th>ZMB</th>\n",
       "      <th>FMB</th>\n",
       "      <th>EKB</th>\n",
       "      <th>IML</th>\n",
       "      <th>XML</th>\n",
       "      <th>WMH</th>\n",
       "      <th>STB</th>\n",
       "      <th>FRC</th>\n",
       "      <th>PAC</th>\n",
       "      <th>OCC</th>\n",
       "      <th>FOL</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "      <td>2524.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>179.172345</td>\n",
       "      <td>176.886688</td>\n",
       "      <td>99.120048</td>\n",
       "      <td>131.644216</td>\n",
       "      <td>136.847861</td>\n",
       "      <td>113.412837</td>\n",
       "      <td>130.766244</td>\n",
       "      <td>120.591125</td>\n",
       "      <td>70.987322</td>\n",
       "      <td>106.856577</td>\n",
       "      <td>97.782488</td>\n",
       "      <td>65.975832</td>\n",
       "      <td>50.009509</td>\n",
       "      <td>115.171949</td>\n",
       "      <td>26.298732</td>\n",
       "      <td>63.545563</td>\n",
       "      <td>27.353803</td>\n",
       "      <td>12.310618</td>\n",
       "      <td>33.667987</td>\n",
       "      <td>39.486529</td>\n",
       "      <td>21.381537</td>\n",
       "      <td>94.975040</td>\n",
       "      <td>96.973059</td>\n",
       "      <td>97.338748</td>\n",
       "      <td>36.108162</td>\n",
       "      <td>52.676704</td>\n",
       "      <td>22.740491</td>\n",
       "      <td>109.347068</td>\n",
       "      <td>109.538827</td>\n",
       "      <td>110.578051</td>\n",
       "      <td>95.690571</td>\n",
       "      <td>35.784865</td>\n",
       "      <td>0.458003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.535998</td>\n",
       "      <td>7.917520</td>\n",
       "      <td>5.808567</td>\n",
       "      <td>7.239258</td>\n",
       "      <td>7.288233</td>\n",
       "      <td>6.372311</td>\n",
       "      <td>7.788730</td>\n",
       "      <td>7.390260</td>\n",
       "      <td>4.788081</td>\n",
       "      <td>5.694080</td>\n",
       "      <td>6.378397</td>\n",
       "      <td>5.534869</td>\n",
       "      <td>4.000187</td>\n",
       "      <td>6.218169</td>\n",
       "      <td>2.325713</td>\n",
       "      <td>4.041097</td>\n",
       "      <td>3.870529</td>\n",
       "      <td>2.135564</td>\n",
       "      <td>2.228324</td>\n",
       "      <td>2.023695</td>\n",
       "      <td>2.410965</td>\n",
       "      <td>5.738572</td>\n",
       "      <td>4.466290</td>\n",
       "      <td>4.239060</td>\n",
       "      <td>4.031754</td>\n",
       "      <td>4.386508</td>\n",
       "      <td>3.043158</td>\n",
       "      <td>7.867309</td>\n",
       "      <td>5.469376</td>\n",
       "      <td>6.629592</td>\n",
       "      <td>5.950560</td>\n",
       "      <td>2.642542</td>\n",
       "      <td>0.498332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>179.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>206.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GOL          NOL          BNL          BBH          XCB  \\\n",
       "count  2524.000000  2524.000000  2524.000000  2524.000000  2524.000000   \n",
       "mean    179.172345   176.886688    99.120048   131.644216   136.847861   \n",
       "std       8.535998     7.917520     5.808567     7.239258     7.288233   \n",
       "min     151.000000   151.000000    83.000000   107.000000   116.000000   \n",
       "25%     173.000000   172.000000    95.000000   127.000000   132.000000   \n",
       "50%     179.000000   177.000000    99.000000   131.000000   137.000000   \n",
       "75%     185.000000   182.000000   103.000000   137.000000   141.000000   \n",
       "max     206.000000   200.000000   120.000000   155.000000   167.000000   \n",
       "\n",
       "               XFB          ZYB          AUB          WCB          ASB  \\\n",
       "count  2524.000000  2524.000000  2524.000000  2524.000000  2524.000000   \n",
       "mean    113.412837   130.766244   120.591125    70.987322   106.856577   \n",
       "std       6.372311     7.788730     7.390260     4.788081     5.694080   \n",
       "min      95.000000   105.000000    98.000000    57.000000    88.000000   \n",
       "25%     109.000000   125.000000   115.000000    68.000000   103.000000   \n",
       "50%     113.000000   131.000000   120.000000    71.000000   107.000000   \n",
       "75%     117.000000   136.000000   125.000000    74.000000   111.000000   \n",
       "max     145.000000   158.000000   149.000000    89.000000   128.000000   \n",
       "\n",
       "               BPL          NPH          NLH          JUB          NLB  \\\n",
       "count  2524.000000  2524.000000  2524.000000  2524.000000  2524.000000   \n",
       "mean     97.782488    65.975832    50.009509   115.171949    26.298732   \n",
       "std       6.378397     5.534869     4.000187     6.218169     2.325713   \n",
       "min      80.000000    48.000000    36.000000    97.000000    19.000000   \n",
       "25%      93.000000    62.750000    47.000000   111.000000    25.000000   \n",
       "50%      98.000000    66.000000    50.000000   115.000000    26.000000   \n",
       "75%     102.000000    70.000000    53.000000   120.000000    28.000000   \n",
       "max     123.000000    82.000000    65.000000   138.000000    35.000000   \n",
       "\n",
       "               MAB          MDH          MDB          OBH          OBB  \\\n",
       "count  2524.000000  2524.000000  2524.000000  2524.000000  2524.000000   \n",
       "mean     63.545563    27.353803    12.310618    33.667987    39.486529   \n",
       "std       4.041097     3.870529     2.135564     2.228324     2.023695   \n",
       "min      52.000000    16.000000     6.000000    26.000000    33.000000   \n",
       "25%      61.000000    25.000000    11.000000    32.000000    38.000000   \n",
       "50%      63.000000    27.000000    12.000000    34.000000    39.000000   \n",
       "75%      66.000000    30.000000    14.000000    35.000000    41.000000   \n",
       "max      78.000000    39.000000    20.000000    41.000000    46.000000   \n",
       "\n",
       "               DKB          ZMB          FMB          EKB          IML  \\\n",
       "count  2524.000000  2524.000000  2524.000000  2524.000000  2524.000000   \n",
       "mean     21.381537    94.975040    96.973059    97.338748    36.108162   \n",
       "std       2.410965     5.738572     4.466290     4.239060     4.031754   \n",
       "min      13.000000    79.000000    81.000000    83.000000    20.000000   \n",
       "25%      20.000000    91.000000    94.000000    95.000000    33.000000   \n",
       "50%      21.000000    95.000000    97.000000    97.000000    36.000000   \n",
       "75%      23.000000    99.000000   100.000000   100.000000    39.000000   \n",
       "max      32.000000   120.000000   112.000000   113.000000    49.000000   \n",
       "\n",
       "               XML          WMH          STB          FRC          PAC  \\\n",
       "count  2524.000000  2524.000000  2524.000000  2524.000000  2524.000000   \n",
       "mean     52.676704    22.740491   109.347068   109.538827   110.578051   \n",
       "std       4.386508     3.043158     7.867309     5.469376     6.629592   \n",
       "min      38.000000    14.000000    81.000000    93.000000    89.000000   \n",
       "25%      50.000000    21.000000   104.000000   106.000000   106.000000   \n",
       "50%      53.000000    23.000000   109.000000   109.000000   111.000000   \n",
       "75%      56.000000    25.000000   115.000000   113.000000   115.000000   \n",
       "max      69.000000    35.000000   140.000000   128.000000   135.000000   \n",
       "\n",
       "               OCC          FOL          Sex  \n",
       "count  2524.000000  2524.000000  2524.000000  \n",
       "mean     95.690571    35.784865     0.458003  \n",
       "std       5.950560     2.642542     0.498332  \n",
       "min      79.000000    27.000000     0.000000  \n",
       "25%      92.000000    34.000000     0.000000  \n",
       "50%      95.000000    36.000000     0.000000  \n",
       "75%     100.000000    37.000000     1.000000  \n",
       "max     118.000000    50.000000     1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full data\n",
    "\n",
    "# Convert M and F to 0 and 1\n",
    "\n",
    "model_data_howell['Sex']= model_data_howell['Sex'].map({'M': 0,'F': 1})\n",
    "\n",
    "model_data_howell['Sex'] = model_data_howell['Sex'].astype(int)\n",
    "\n",
    "model_data_howell.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOL</th>\n",
       "      <th>NOL</th>\n",
       "      <th>BNL</th>\n",
       "      <th>BBH</th>\n",
       "      <th>XCB</th>\n",
       "      <th>XFB</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>AUB</th>\n",
       "      <th>WCB</th>\n",
       "      <th>ASB</th>\n",
       "      <th>BPL</th>\n",
       "      <th>NPH</th>\n",
       "      <th>NLH</th>\n",
       "      <th>JUB</th>\n",
       "      <th>NLB</th>\n",
       "      <th>MAB</th>\n",
       "      <th>MDH</th>\n",
       "      <th>MDB</th>\n",
       "      <th>OBH</th>\n",
       "      <th>OBB</th>\n",
       "      <th>DKB</th>\n",
       "      <th>ZMB</th>\n",
       "      <th>FMB</th>\n",
       "      <th>EKB</th>\n",
       "      <th>IML</th>\n",
       "      <th>XML</th>\n",
       "      <th>WMH</th>\n",
       "      <th>STB</th>\n",
       "      <th>FRC</th>\n",
       "      <th>PAC</th>\n",
       "      <th>OCC</th>\n",
       "      <th>FOL</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>524.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>180.442748</td>\n",
       "      <td>177.931298</td>\n",
       "      <td>99.812977</td>\n",
       "      <td>132.652672</td>\n",
       "      <td>137.679389</td>\n",
       "      <td>113.992366</td>\n",
       "      <td>133.007634</td>\n",
       "      <td>122.110687</td>\n",
       "      <td>71.730916</td>\n",
       "      <td>108.068702</td>\n",
       "      <td>99.230916</td>\n",
       "      <td>67.041985</td>\n",
       "      <td>50.463740</td>\n",
       "      <td>116.933206</td>\n",
       "      <td>26.496183</td>\n",
       "      <td>64.675573</td>\n",
       "      <td>28.280534</td>\n",
       "      <td>12.860687</td>\n",
       "      <td>33.576336</td>\n",
       "      <td>39.979008</td>\n",
       "      <td>21.812977</td>\n",
       "      <td>96.601145</td>\n",
       "      <td>98.309160</td>\n",
       "      <td>98.545802</td>\n",
       "      <td>36.717557</td>\n",
       "      <td>53.645038</td>\n",
       "      <td>23.167939</td>\n",
       "      <td>109.604962</td>\n",
       "      <td>110.049618</td>\n",
       "      <td>112.017176</td>\n",
       "      <td>96.150763</td>\n",
       "      <td>36.137405</td>\n",
       "      <td>0.303435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.450817</td>\n",
       "      <td>8.843825</td>\n",
       "      <td>6.271071</td>\n",
       "      <td>7.406367</td>\n",
       "      <td>7.722498</td>\n",
       "      <td>6.868885</td>\n",
       "      <td>8.416042</td>\n",
       "      <td>7.752330</td>\n",
       "      <td>5.204620</td>\n",
       "      <td>5.825297</td>\n",
       "      <td>6.943787</td>\n",
       "      <td>6.039240</td>\n",
       "      <td>4.302676</td>\n",
       "      <td>6.962157</td>\n",
       "      <td>2.794762</td>\n",
       "      <td>4.511054</td>\n",
       "      <td>3.906107</td>\n",
       "      <td>2.258966</td>\n",
       "      <td>2.493566</td>\n",
       "      <td>2.385732</td>\n",
       "      <td>2.555567</td>\n",
       "      <td>6.372989</td>\n",
       "      <td>5.459728</td>\n",
       "      <td>5.253407</td>\n",
       "      <td>4.108518</td>\n",
       "      <td>4.632576</td>\n",
       "      <td>2.870441</td>\n",
       "      <td>8.242643</td>\n",
       "      <td>5.836312</td>\n",
       "      <td>7.352221</td>\n",
       "      <td>5.661431</td>\n",
       "      <td>2.915019</td>\n",
       "      <td>0.460181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>158.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>174.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>92.750000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>186.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>142.250000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>212.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              GOL         NOL         BNL         BBH         XCB         XFB  \\\n",
       "count  524.000000  524.000000  524.000000  524.000000  524.000000  524.000000   \n",
       "mean   180.442748  177.931298   99.812977  132.652672  137.679389  113.992366   \n",
       "std      9.450817    8.843825    6.271071    7.406367    7.722498    6.868885   \n",
       "min    158.000000  156.000000   80.000000  103.000000  116.000000   95.000000   \n",
       "25%    174.000000  172.000000   96.000000  128.000000  132.000000  109.000000   \n",
       "50%    180.000000  177.000000  100.000000  132.000000  137.000000  114.000000   \n",
       "75%    186.000000  184.000000  103.000000  138.000000  142.250000  119.000000   \n",
       "max    212.000000  209.000000  125.000000  159.000000  161.000000  141.000000   \n",
       "\n",
       "              ZYB         AUB         WCB         ASB         BPL         NPH  \\\n",
       "count  524.000000  524.000000  524.000000  524.000000  524.000000  524.000000   \n",
       "mean   133.007634  122.110687   71.730916  108.068702   99.230916   67.041985   \n",
       "std      8.416042    7.752330    5.204620    5.825297    6.943787    6.039240   \n",
       "min    112.000000  104.000000   60.000000   90.000000   80.000000   49.000000   \n",
       "25%    128.000000  117.000000   68.000000  104.000000   95.000000   63.000000   \n",
       "50%    133.000000  122.000000   71.000000  108.000000   99.000000   67.000000   \n",
       "75%    138.000000  127.000000   75.000000  112.000000  103.000000   71.000000   \n",
       "max    157.000000  145.000000   88.000000  133.000000  131.000000   90.000000   \n",
       "\n",
       "              NLH         JUB         NLB         MAB         MDH         MDB  \\\n",
       "count  524.000000  524.000000  524.000000  524.000000  524.000000  524.000000   \n",
       "mean    50.463740  116.933206   26.496183   64.675573   28.280534   12.860687   \n",
       "std      4.302676    6.962157    2.794762    4.511054    3.906107    2.258966   \n",
       "min     35.000000   98.000000   20.000000   53.000000   17.000000    5.000000   \n",
       "25%     47.000000  112.000000   25.000000   62.000000   26.000000   11.000000   \n",
       "50%     50.000000  117.000000   26.000000   64.000000   28.000000   13.000000   \n",
       "75%     53.000000  122.000000   28.000000   68.000000   31.000000   14.000000   \n",
       "max     68.000000  141.000000   55.000000   86.000000   39.000000   22.000000   \n",
       "\n",
       "              OBH         OBB         DKB         ZMB         FMB         EKB  \\\n",
       "count  524.000000  524.000000  524.000000  524.000000  524.000000  524.000000   \n",
       "mean    33.576336   39.979008   21.812977   96.601145   98.309160   98.545802   \n",
       "std      2.493566    2.385732    2.555567    6.372989    5.459728    5.253407   \n",
       "min     27.000000   34.000000   16.000000   78.000000   84.000000   86.000000   \n",
       "25%     32.000000   38.000000   20.000000   92.750000   94.000000   95.000000   \n",
       "50%     33.500000   40.000000   22.000000   97.000000   98.000000   99.000000   \n",
       "75%     35.000000   41.000000   24.000000  101.000000  102.000000  102.000000   \n",
       "max     43.000000   49.000000   30.000000  117.000000  124.000000  118.000000   \n",
       "\n",
       "              IML         XML         WMH         STB         FRC         PAC  \\\n",
       "count  524.000000  524.000000  524.000000  524.000000  524.000000  524.000000   \n",
       "mean    36.717557   53.645038   23.167939  109.604962  110.049618  112.017176   \n",
       "std      4.108518    4.632576    2.870441    8.242643    5.836312    7.352221   \n",
       "min     22.000000   39.000000   15.000000   75.000000   94.000000   89.000000   \n",
       "25%     34.000000   51.000000   21.000000  105.000000  106.000000  107.000000   \n",
       "50%     37.000000   53.000000   23.000000  110.000000  110.000000  112.000000   \n",
       "75%     40.000000   57.000000   25.000000  115.000000  114.000000  117.000000   \n",
       "max     50.000000   68.000000   32.000000  141.000000  136.000000  134.000000   \n",
       "\n",
       "              OCC         FOL         Sex  \n",
       "count  524.000000  524.000000  524.000000  \n",
       "mean    96.150763   36.137405    0.303435  \n",
       "std      5.661431    2.915019    0.460181  \n",
       "min     80.000000   25.000000    0.000000  \n",
       "25%     92.000000   34.000000    0.000000  \n",
       "50%     96.000000   36.000000    0.000000  \n",
       "75%    100.000000   38.000000    1.000000  \n",
       "max    113.000000   49.000000    1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "\n",
    "model_data_howell_test['Sex']= model_data_howell_test['Sex'].map({'M': 0,'F': 1})\n",
    "\n",
    "model_data_howell_test['Sex'] = model_data_howell_test['Sex'].astype(int)\n",
    "\n",
    "model_data_howell_test.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the dataset with the test set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOL</th>\n",
       "      <th>NOL</th>\n",
       "      <th>BNL</th>\n",
       "      <th>BBH</th>\n",
       "      <th>XCB</th>\n",
       "      <th>XFB</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>AUB</th>\n",
       "      <th>WCB</th>\n",
       "      <th>ASB</th>\n",
       "      <th>BPL</th>\n",
       "      <th>NPH</th>\n",
       "      <th>NLH</th>\n",
       "      <th>JUB</th>\n",
       "      <th>NLB</th>\n",
       "      <th>MAB</th>\n",
       "      <th>MDH</th>\n",
       "      <th>MDB</th>\n",
       "      <th>OBH</th>\n",
       "      <th>OBB</th>\n",
       "      <th>DKB</th>\n",
       "      <th>ZMB</th>\n",
       "      <th>FMB</th>\n",
       "      <th>EKB</th>\n",
       "      <th>IML</th>\n",
       "      <th>XML</th>\n",
       "      <th>WMH</th>\n",
       "      <th>STB</th>\n",
       "      <th>FRC</th>\n",
       "      <th>PAC</th>\n",
       "      <th>OCC</th>\n",
       "      <th>FOL</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "      <td>3048.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>179.390748</td>\n",
       "      <td>177.066273</td>\n",
       "      <td>99.239173</td>\n",
       "      <td>131.817585</td>\n",
       "      <td>136.990814</td>\n",
       "      <td>113.512467</td>\n",
       "      <td>131.151575</td>\n",
       "      <td>120.852362</td>\n",
       "      <td>71.115157</td>\n",
       "      <td>107.064961</td>\n",
       "      <td>98.031496</td>\n",
       "      <td>66.159121</td>\n",
       "      <td>50.087598</td>\n",
       "      <td>115.474738</td>\n",
       "      <td>26.332677</td>\n",
       "      <td>63.739829</td>\n",
       "      <td>27.513123</td>\n",
       "      <td>12.405184</td>\n",
       "      <td>33.652231</td>\n",
       "      <td>39.571194</td>\n",
       "      <td>21.455709</td>\n",
       "      <td>95.254593</td>\n",
       "      <td>97.202756</td>\n",
       "      <td>97.546260</td>\n",
       "      <td>36.212927</td>\n",
       "      <td>52.843176</td>\n",
       "      <td>22.813976</td>\n",
       "      <td>109.391404</td>\n",
       "      <td>109.626640</td>\n",
       "      <td>110.825459</td>\n",
       "      <td>95.769685</td>\n",
       "      <td>35.845472</td>\n",
       "      <td>0.431430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.711690</td>\n",
       "      <td>8.092398</td>\n",
       "      <td>5.895397</td>\n",
       "      <td>7.276989</td>\n",
       "      <td>7.370092</td>\n",
       "      <td>6.462929</td>\n",
       "      <td>7.943846</td>\n",
       "      <td>7.474485</td>\n",
       "      <td>4.869433</td>\n",
       "      <td>5.734159</td>\n",
       "      <td>6.500940</td>\n",
       "      <td>5.638137</td>\n",
       "      <td>4.056688</td>\n",
       "      <td>6.385752</td>\n",
       "      <td>2.413496</td>\n",
       "      <td>4.146904</td>\n",
       "      <td>3.891770</td>\n",
       "      <td>2.166866</td>\n",
       "      <td>2.275954</td>\n",
       "      <td>2.098224</td>\n",
       "      <td>2.441439</td>\n",
       "      <td>5.883522</td>\n",
       "      <td>4.678460</td>\n",
       "      <td>4.452406</td>\n",
       "      <td>4.050907</td>\n",
       "      <td>4.444052</td>\n",
       "      <td>3.018025</td>\n",
       "      <td>7.932312</td>\n",
       "      <td>5.536557</td>\n",
       "      <td>6.779841</td>\n",
       "      <td>5.903510</td>\n",
       "      <td>2.694134</td>\n",
       "      <td>0.495357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>174.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>179.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>117.250000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>212.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GOL          NOL          BNL          BBH          XCB  \\\n",
       "count  3048.000000  3048.000000  3048.000000  3048.000000  3048.000000   \n",
       "mean    179.390748   177.066273    99.239173   131.817585   136.990814   \n",
       "std       8.711690     8.092398     5.895397     7.276989     7.370092   \n",
       "min     151.000000   151.000000    80.000000   103.000000   116.000000   \n",
       "25%     174.000000   172.000000    95.000000   127.000000   132.000000   \n",
       "50%     179.000000   177.000000    99.000000   132.000000   137.000000   \n",
       "75%     185.000000   182.000000   103.000000   137.000000   141.000000   \n",
       "max     212.000000   209.000000   125.000000   159.000000   167.000000   \n",
       "\n",
       "               XFB          ZYB          AUB          WCB          ASB  \\\n",
       "count  3048.000000  3048.000000  3048.000000  3048.000000  3048.000000   \n",
       "mean    113.512467   131.151575   120.852362    71.115157   107.064961   \n",
       "std       6.462929     7.943846     7.474485     4.869433     5.734159   \n",
       "min      95.000000   105.000000    98.000000    57.000000    88.000000   \n",
       "25%     109.000000   125.000000   116.000000    68.000000   103.000000   \n",
       "50%     113.000000   131.000000   121.000000    71.000000   107.000000   \n",
       "75%     117.250000   137.000000   126.000000    74.000000   111.000000   \n",
       "max     145.000000   158.000000   149.000000    89.000000   133.000000   \n",
       "\n",
       "               BPL          NPH          NLH          JUB          NLB  \\\n",
       "count  3048.000000  3048.000000  3048.000000  3048.000000  3048.000000   \n",
       "mean     98.031496    66.159121    50.087598   115.474738    26.332677   \n",
       "std       6.500940     5.638137     4.056688     6.385752     2.413496   \n",
       "min      80.000000    48.000000    35.000000    97.000000    19.000000   \n",
       "25%      94.000000    63.000000    47.000000   111.000000    25.000000   \n",
       "50%      98.000000    66.000000    50.000000   115.000000    26.000000   \n",
       "75%     102.000000    70.000000    53.000000   120.000000    28.000000   \n",
       "max     131.000000    90.000000    68.000000   141.000000    55.000000   \n",
       "\n",
       "               MAB          MDH          MDB          OBH          OBB  \\\n",
       "count  3048.000000  3048.000000  3048.000000  3048.000000  3048.000000   \n",
       "mean     63.739829    27.513123    12.405184    33.652231    39.571194   \n",
       "std       4.146904     3.891770     2.166866     2.275954     2.098224   \n",
       "min      52.000000    16.000000     5.000000    26.000000    33.000000   \n",
       "25%      61.000000    25.000000    11.000000    32.000000    38.000000   \n",
       "50%      64.000000    28.000000    12.000000    34.000000    40.000000   \n",
       "75%      66.000000    30.000000    14.000000    35.000000    41.000000   \n",
       "max      86.000000    39.000000    22.000000    43.000000    49.000000   \n",
       "\n",
       "               DKB          ZMB          FMB          EKB          IML  \\\n",
       "count  3048.000000  3048.000000  3048.000000  3048.000000  3048.000000   \n",
       "mean     21.455709    95.254593    97.202756    97.546260    36.212927   \n",
       "std       2.441439     5.883522     4.678460     4.452406     4.050907   \n",
       "min      13.000000    78.000000    81.000000    83.000000    20.000000   \n",
       "25%      20.000000    91.000000    94.000000    95.000000    33.000000   \n",
       "50%      21.000000    95.000000    97.000000    97.000000    36.000000   \n",
       "75%      23.000000    99.000000   100.000000   100.000000    39.000000   \n",
       "max      32.000000   120.000000   124.000000   118.000000    50.000000   \n",
       "\n",
       "               XML          WMH          STB          FRC          PAC  \\\n",
       "count  3048.000000  3048.000000  3048.000000  3048.000000  3048.000000   \n",
       "mean     52.843176    22.813976   109.391404   109.626640   110.825459   \n",
       "std       4.444052     3.018025     7.932312     5.536557     6.779841   \n",
       "min      38.000000    14.000000    75.000000    93.000000    89.000000   \n",
       "25%      50.000000    21.000000   104.000000   106.000000   106.000000   \n",
       "50%      53.000000    23.000000   109.000000   109.000000   111.000000   \n",
       "75%      56.000000    25.000000   115.000000   113.000000   115.000000   \n",
       "max      69.000000    35.000000   141.000000   136.000000   135.000000   \n",
       "\n",
       "               OCC          FOL          Sex  \n",
       "count  3048.000000  3048.000000  3048.000000  \n",
       "mean     95.769685    35.845472     0.431430  \n",
       "std       5.903510     2.694134     0.495357  \n",
       "min      79.000000    25.000000     0.000000  \n",
       "25%      92.000000    34.000000     0.000000  \n",
       "50%      96.000000    36.000000     0.000000  \n",
       "75%     100.000000    38.000000     1.000000  \n",
       "max     118.000000    50.000000     1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_set = pd.concat([model_data_howell, model_data_howell_test])\n",
    "\n",
    "full_set = full_set.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "full_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_set.drop('Sex', axis = 1).values\n",
    "y = full_set['Sex']\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification without hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_names = [\n",
    "    \"Logistic Regression\", \n",
    "    \"Decision Tree Classifier\", \n",
    "    \"Support Vector Machines\", \n",
    "    \"Gaussian Process Classifier\", \n",
    "    \"Gradient Boosting Classifier\", \n",
    "    \"Random Forest Classifier\",\n",
    "    \"Ada Boost Classifier\", \n",
    "    \"Extra Trees Classifier\", \n",
    "    \"Gaussian Naive Bayes\", \n",
    "    \"KNNeighbors Classifier\",\n",
    "    \"Linear Discriminant Analysis\", \n",
    "    \"Quadratic Discriminant Analysis\", \n",
    "    \"XGBClassifier\", \n",
    "    \"Light Gradient Boosting Classifier\"\n",
    "]\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    SVC(),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    XGBClassifier(),\n",
    "    lgb.LGBMClassifier()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n"
     ]
    }
   ],
   "source": [
    "dataset_scores_list = []\n",
    "\n",
    "for name, clf in zip(classifier_names, classifiers):\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)*100\n",
    "\n",
    "    dataset_scores_list.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[81.31147540983606,\n",
       " 75.84699453551913,\n",
       " 82.18579234972677,\n",
       " 76.83060109289617,\n",
       " 83.49726775956285,\n",
       " 82.18579234972677,\n",
       " 82.07650273224044,\n",
       " 82.40437158469945,\n",
       " 79.45355191256832,\n",
       " 80.87431693989072,\n",
       " 85.46448087431693,\n",
       " 82.29508196721311,\n",
       " 83.16939890710383,\n",
       " 83.82513661202185]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Howells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>81.311475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>75.846995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>82.185792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Process Classifier</th>\n",
       "      <td>76.830601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>83.497268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>82.185792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost Classifier</th>\n",
       "      <td>82.076503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Trees Classifier</th>\n",
       "      <td>82.404372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>79.453552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNeighbors Classifier</th>\n",
       "      <td>80.874317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Discriminant Analysis</th>\n",
       "      <td>85.464481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quadratic Discriminant Analysis</th>\n",
       "      <td>82.295082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>83.169399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Light Gradient Boosting Classifier</th>\n",
       "      <td>83.825137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Howells\n",
       "Logistic Regression                 81.311475\n",
       "Decision Tree Classifier            75.846995\n",
       "Support Vector Machines             82.185792\n",
       "Gaussian Process Classifier         76.830601\n",
       "Gradient Boosting Classifier        83.497268\n",
       "Random Forest Classifier            82.185792\n",
       "Ada Boost Classifier                82.076503\n",
       "Extra Trees Classifier              82.404372\n",
       "Gaussian Naive Bayes                79.453552\n",
       "KNNeighbors Classifier              80.874317\n",
       "Linear Discriminant Analysis        85.464481\n",
       "Quadratic Discriminant Analysis     82.295082\n",
       "XGBClassifier                       83.169399\n",
       "Light Gradient Boosting Classifier  83.825137"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(index=classifier_names)\n",
    "results['Howells'] = dataset_scores_list\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the table to LateX format\n",
    "\n",
    "# print(results.to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8131147540983606"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "              search_spaces={'C': array([0.010000, 0.100000, 1.000000, 10.000000, 100.000000]),\n",
       "                             'max_iter': [2500], 'random_state': [0]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the logistic regression model\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "parameters = {\n",
    "    'C': np.logspace(-2,2,5),\n",
    "    'max_iter': [2500],\n",
    "    'random_state': [0]\n",
    "}\n",
    "\n",
    "clf  = BayesSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('C', 0.01), ('max_iter', 2500), ('random_state', 0)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8655737704918033"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to export a model use the following command\n",
    "\n",
    "# pickle.dump(model, open(\"logreg_model_howell.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8218579234972677"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vector machines\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(),\n",
       "             param_grid={'C': array([0.010000, 0.100000, 1.000000, 10.000000, 100.000000])})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the Support Vector Machine model\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "parameters = {\n",
    "    'C': np.logspace(-2,2,5)\n",
    "     #'kernel': ['rbf','linear']\n",
    "}\n",
    "\n",
    "clf  = GridSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8579234972677595"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(**clf.best_params_, probability=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(model, open(\"svm_model_howell.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8207650273224044"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kNN classifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15, 16, 17, 18, 19],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the kNN classifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'n_neighbors': list(range(1,21)),\n",
    "#      'weights' : ['uniform', 'distance'],\n",
    "#       'metric' : ['euclidean', 'manhattan'],\n",
    "    'leaf_size': list(range(1,20))\n",
    "             }\n",
    "\n",
    "clf  = GridSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 1, 'n_neighbors': 15}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8185792349726776"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065573770491803"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.000000, 0.811131, 0.657933, 0.533670, 0.432876, 0.351119,\n",
       "       0.284804, 0.231013, 0.187382, 0.151991, 0.123285, 0.100000,\n",
       "       0.081113, 0.065793, 0.053367, 0.043288, 0.035112, 0.028480,\n",
       "       0.023101, 0.018738, 0.015199, 0.012328, 0.010000, 0.008111,\n",
       "       0.006579, 0.005337, 0.004329, 0.003511, 0.002848, 0.002310,\n",
       "       0.0...\n",
       "       0.000004, 0.000003, 0.000002, 0.000002, 0.000002, 0.000001,\n",
       "       0.000001, 0.000001, 0.000001, 0.000001, 0.000000, 0.000000,\n",
       "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
       "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
       "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
       "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
       "       0.000000, 0.000000, 0.000000, 0.000000])})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the Gaussian Naive Bayes classifier\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "parameters = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "             }\n",
    "\n",
    "clf  = GridSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 0.0657933224657568}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.805464480874317"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8644808743169399"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LinearDiscriminantAnalysis(),\n",
       "             param_grid={'solver': ['svd', 'lsqr', 'eigen']})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the Linear Discriminant Analysis classifier\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "parameters = {\n",
    "    'solver' : ['svd', 'lsqr', 'eigen']\n",
    "             }\n",
    "\n",
    "clf  = GridSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'svd'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8644808743169399"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(model, open(\"lda_model_howell.dat\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833879781420765"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quadratic Discriminant Analysis\n",
    "\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=QuadraticDiscriminantAnalysis(),\n",
       "             param_grid={'reg_param': [0.0, 0.1, 0.2, 0.3, 0.4]})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the Quadratic Discriminant Analysis classifier\n",
    "\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "parameters = {\n",
    "    'reg_param' : [0., 0.1, 0.2, 0.3, 0.4]\n",
    "             }\n",
    "\n",
    "clf  = GridSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_param': 0.1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327868852459016"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quadratic Discriminant Analysis\n",
    "\n",
    "model = QuadraticDiscriminantAnalysis(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760655737704918"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 15, 20, 30, 40, 120,\n",
       "                                       150]})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the Decision Tree Classifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'criterion':['entropy','gini'],\n",
    "    'max_depth':[1,2,3,4,5,6,7,15,20,30,40,120,150]\n",
    "}\n",
    "\n",
    "clf  = GridSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 2}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8153005464480875"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8306010928961749"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the Random Forest Classifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "clf  = RandomizedSearchCV(model, param_distributions=random_grid, n_iter = 20, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 2000,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 40,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327868852459016\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8426229508196721"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost Classifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=10, estimator=XGBClassifier(),\n",
       "              search_spaces={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                             'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                             'max_depth': [3, 4, 5],\n",
       "                             'min_child_weight': [1, 5, 10],\n",
       "                             'subsample': [0.6, 0.8, 1.0]})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the XGBoost Classifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "parameters = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "clf  = BayesSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('colsample_bytree', 1.0),\n",
       "             ('gamma', 1.5),\n",
       "             ('max_depth', 4),\n",
       "             ('min_child_weight', 1),\n",
       "             ('subsample', 0.6)])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8524590163934426\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7683060109289618"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Process Classifier\n",
    "\n",
    "model = GaussianProcessClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 664, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 212, in fit\n",
      "    optima = [self._constrained_optimization(obj_func,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 445, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 204, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 364, in log_marginal_likelihood\n",
      "    self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpc.py\", line 417, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 150-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:402: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.767732 nan 0.788722 0.876962 0.568570]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianProcessClassifier(),\n",
       "             param_grid={'kernel': [1**2 * RBF(length_scale=1),\n",
       "                                    1**2 * DotProduct(sigma_0=1),\n",
       "                                    1**2 * Matern(length_scale=1, nu=1.5),\n",
       "                                    1**2 * RationalQuadratic(alpha=1, length_scale=1),\n",
       "                                    1**2 * WhiteKernel(noise_level=1)]})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the GaussianProcessClassifier\n",
    "\n",
    "model = GaussianProcessClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'kernel' : [1*RBF(), 1*DotProduct(), 1*Matern(),  1*RationalQuadratic(), 1*WhiteKernel()]\n",
    "}\n",
    "\n",
    "clf  = GridSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853551912568306\n"
     ]
    }
   ],
   "source": [
    "model = GaussianProcessClassifier(**clf.best_params_, max_iter_predict = 1000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360655737704918"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=10, estimator=GradientBoostingClassifier(),\n",
       "              search_spaces={'learning_rate': [0.01, 0.1, 1, 10, 100],\n",
       "                             'max_depth': [1, 3, 5, 7, 9],\n",
       "                             'n_estimators': [5, 50, 250, 500]})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the Gradient Boosting Classifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,50,250,500],\n",
    "    \"max_depth\":[1,3,5,7,9],\n",
    "    \"learning_rate\":[0.01,0.1,1,10,100]\n",
    "}\n",
    "\n",
    "clf  = BayesSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.1), ('max_depth', 5), ('n_estimators', 500)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8491803278688524\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8207650273224044"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada Boost Classifier\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:561: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(estimator_weight *\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:155: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sample_weight /= sample_weight_sum\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 443, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 130, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 503, in _boost\n",
      "    return self._boost_real(iboost, X, y, sample_weight, random_state)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 513, in _boost_real\n",
      "    estimator.fit(X, y, sample_weight=sample_weight)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 298, in fit\n",
      "    sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1376, in _check_sample_weight\n",
      "    sample_weight = check_array(\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 720, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/cconsta1/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.776571 0.802162 0.828727 0.832347 0.802482 0.833659 0.851054 0.852031\n",
      " 0.805449 0.840879 0.852027 0.847762 0.694541 0.226707 0.226707 0.226707\n",
      " nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=AdaBoostClassifier(),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 1, 10, 100],\n",
       "                         'n_estimators': [5, 50, 250, 500]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the Gradient Boosting Classifier\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,50,250,500],\n",
    "    \"learning_rate\":[0.01,0.1,1,10,100]\n",
    "}\n",
    "\n",
    "clf  = GridSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'n_estimators': 500}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8349726775956284\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8207650273224044"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra trees regressor\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=ExtraTreesClassifier(),\n",
       "                   param_distributions={'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 11,\n",
       "                                                             12, 13, 14, 15, 16,\n",
       "                                                             17, 18, 19],\n",
       "                                        'min_samples_split': [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9, 10, 11,\n",
       "                                                              12, 13, 14, 15,\n",
       "                                                              16, 17, 18, 19],\n",
       "                                        'n_estimators': [50, 75, 100, 125]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "parameters = {\n",
    "        'n_estimators': list(range(50,126,25)),\n",
    "        'min_samples_leaf': list(range(1,20,1)),\n",
    "        'min_samples_split': list(range(1,20,1))\n",
    "    }\n",
    "\n",
    "clf  = RandomizedSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 75, 'min_samples_split': 11, 'min_samples_leaf': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8316939890710382\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8382513661202186"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Light boosting regressor\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=LGBMClassifier(),\n",
       "                   param_distributions={'min_child_samples': [20, 30, 50, 100],\n",
       "                                        'min_child_weight': [1e-05, 0.001, 0.01,\n",
       "                                                             0.1, 1],\n",
       "                                        'num_leaves': [5, 10, 20, 31, 50, 100],\n",
       "                                        'reg_alpha': [0, 0.1, 1],\n",
       "                                        'reg_lambda': [0, 0.1, 1, 5, 10]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing the LGBMClassifier\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'num_leaves': [5, 10, 20, 31, 50, 100], \n",
    "    'min_child_samples': [20, 30, 50 , 100], \n",
    "     'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1],\n",
    "     'reg_alpha': [0, 1e-1, 1],\n",
    "    'reg_lambda': [0, 1e-1, 1, 5, 10]\n",
    "    }\n",
    "\n",
    "clf  = RandomizedSearchCV(model, parameters, cv=10, return_train_score=False)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_lambda': 0.1,\n",
       " 'reg_alpha': 0.1,\n",
       " 'num_leaves': 50,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_child_samples': 30}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839344262295082\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(**clf.best_params_)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
